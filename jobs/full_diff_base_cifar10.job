#!/bin/bash
#SBATCH --account=def-functor
#SBATCH --gres=gpu:1
#SBATCH --mem=8000
#SBATCH --time=0-02:0
#SBATCH --output=%x_%a.out
#SBATCH --mail-user=fsharifb@sfu.ca
#SBATCH --mail-type=ALL
#SBATCH --array=0-5183

# %x is the job name

SLURM_JOB_NAME=${SLURM_JOB_NAME:-"oct4"}
SLURM_ARRAY_TASK_ID=100

BASE_NETS=(two_fc diff_fc)
NETS=(reg fcN featNRO_R featNRO_S featNRO_Th featNPO_R featNPO_S featNPO_Th featNRO_Smax_g featNRO_Smax_ch featNPO_Smax_g featNPO_Smax_ch featNRO_Smax_g_ch featNPO_Smax_g_ch featNRO_S_g_ch featNPO_S_g_ch)
REGULARIZATION_TYPES=(l1 l2 cos)
REGULARIZATION_RATES=(0 0.01 0.1 1)
NON_LINEARS=(none relu sigmoid tanh)

# these two are hardcoded to cut down on experiments
FREEZES=('' '--unfreeze-all')
AUGMENTS=('' '-a')
FREEZE_TEXTS=(freeze unfreeze)
AUGMENT_TEXTS=(no_augment augment)
let FREEZE_INDEX=1
let AUGMENT_INDEX=0

BASE_NETS_C=${#BASE_NETS[@]}
NETS_C=${#NETS[@]}
NON_LINEARS_C=${#NON_LINEARS[@]}
REGULARIZATION_TYPES_C=${#REGULARIZATION_TYPES[@]}
REGULARIZATION_RATES_C=${#REGULARIZATION_RATES[@]}

JOB_NUM=${SLURM_ARRAY_TASK_ID}

let NON_LINEAR_INDEX=${JOB_NUM}%${NON_LINEARS_C}
let JOB_NUM=${JOB_NUM}/${NON_LINEARS_C}
let REGULARIZATION_RATE_INDEX=${JOB_NUM}%${REGULARIZATION_RATES_C}
let JOB_NUM=${JOB_NUM}/${REGULARIZATION_RATES_C}
let REGULARIZATION_TYPE_INDEX=${JOB_NUM}%${REGULARIZATION_TYPES_C}
let JOB_NUM=${JOB_NUM}/${REGULARIZATION_TYPES_C}
let NET_INDEX=${JOB_NUM}%${NETS_C}
let BASE_NET_INDEX=${JOB_NUM}/${NETS_C}

BASE_NET=${BASE_NETS[${BASE_NET_INDEX}]}
NET=${NETS[${NET_INDEX}]}
REGULARIZATION_TYPE=${REGULARIZATION_TYPES[${REGULARIZATION_TYPE_INDEX}]}
REGULARIZATION_RATE=${REGULARIZATION_RATES[${REGULARIZATION_RATE_INDEX}]}
NON_LINEAR=${NON_LINEARS[${NON_LINEAR_INDEX}]}
FREEZE=${FREEZES[${FREEZE_INDEX}]}
FREEZE_TEXT=${FREEZE_TEXTS[${FREEZE_INDEX}]}
AUGMENT=${AUGMENTS[${AUGMENT_INDEX}]}
AUGMENT_TEXT=${AUGMENT_TEXTS[${AUGMENT_INDEX}]}

CHECKPOINT=outputs/diff_base_cifar10/${BASE_NET}_${NON_LINEAR}_regul-${REGULARIZATION_TYPE}-at-${REGULARIZATION_RATE}_cifar10.model
FILE_NAME=${SLURM_ARRAY_TASK_ID}_${BASE_NET}_${NET}_${NON_LINEAR}_${FREEZE_TEXT}_${AUGMENT_TEXT}_regul-${REGULARIZATION_TYPE}-at-${REGULARIZATION_RATE}_cifar10
OUTPUT_FOLDER=${OUTPUT_FOLDER:-running/${SLURM_JOB_NAME}}
OUTPUT_FOLDER=testing/${SLURM_JOB_NAME}

source startup.sh

mkdir -p ${OUTPUT_FOLDER}

echo $CHECKPOINT
echo "python model.py -e 120 -d '../datasets' --cifar-10 -s ${AUGMENT} -m ${OUTPUT_FOLDER}/${FILE_NAME}.model  -l ${CHECKPOINT} --non-linear=${NON_LINEAR} -x --base-net=${BASE_NET} -n ${NET} --net-args nonlinear=${NON_LINEAR} regularization_type=${REGULARIZATION_TYPE} regularization_rate=${REGULARIZATION_RATE} ${FREEZE} > ${OUTPUT_FOLDER}/${FILE_NAME}.out"
python model.py -e 3 --limit 10 -d '../datasets' --cifar-10 -s ${AUGMENT} -m ${OUTPUT_FOLDER}/${FILE_NAME}.model  -l ${CHECKPOINT} --non-linear=${NON_LINEAR} -x --base-net=${BASE_NET} -n ${NET} --net-args nonlinear=${NON_LINEAR} regularization_type=${REGULARIZATION_TYPE} regularization_rate=${REGULARIZATION_RATE} ${FREEZE}

#python model.py -e 120 -d '../datasets' --cifar-10 -s ${AUGMENT} -m ${OUTPUT_FOLDER}/${FILE_NAME}_retrained.model  -l ${OUTPUT_FOLDER}/${FILE_NAME}.model --non-linear=${NON_LINEAR} -x --base-net=${BASE_NET} -n ${NET} --net-args nonlinear=${NON_LINEAR} regularization_type=${REGULARIZATION_TYPE} regularization_rate=${REGULARIZATION_RATE} ${FREEZE} > ${OUTPUT_FOLDER}/${FILE_NAME}_retrained.out

